# ContextWeaver

<p align="center">
  <strong>ğŸ§µ A Context Weaving Engine for AI Agents</strong>
</p>

<p align="center">
  <em>Semantic Code Retrieval for AI Agents â€” Hybrid Search â€¢ Graph Expansion â€¢ Token-Aware Packing â€¢ Prompt Enhancer</em>
</p>

<p align="center">
  English | <a href="./README.md">ä¸­æ–‡</a>
</p>

---

> **Fork Note**: This project is forked from [hsingjui/ContextWeaver](https://github.com/hsingjui/ContextWeaver), with the addition of a **Prompt Enhancer** feature supporting OpenAI / Claude / Gemini multi-LLM endpoints, CLI commands, and Web UI interaction.

**ContextWeaver** is a semantic retrieval engine designed for AI coding assistants. It uses hybrid search (vector + lexical), intelligent context expansion, and token-aware packing to provide precise, relevant, and context-complete code snippets for LLMs.

<p align="center">
  <img src="docs/architecture.png" alt="ContextWeaver Architecture" width="800" />
</p>

## âœ¨ Key Features

### ğŸ” Hybrid Retrieval Engine
- **Vector Retrieval**: Deep understanding via semantic similarity
- **Lexical Retrieval (FTS)**: Exact matching of function names, class names, and technical terms
- **RRF Fusion (Reciprocal Rank Fusion)**: Intelligent fusion of multi-path recall results

### ğŸ§  AST-Based Semantic Chunking
- **Tree-sitter Parsing**: Supports TypeScript, JavaScript, Python, Go, Java, Rust, C, C++, C# â€” 9 languages
- **Dual-Text Strategy**: `displayCode` for display, `vectorText` for embedding
- **Gap-Aware Merging**: Smart handling of code gaps while preserving semantic integrity
- **Breadcrumb Injection**: Hierarchical path in vector text improves retrieval recall

### ğŸ“Š Three-Phase Context Expansion
- **E1 Neighbor Expansion**: Adjacent chunks in the same file for code block completeness
- **E2 Breadcrumb Completion**: Other methods under the same class/function for structural understanding
- **E3 Import Resolution**: Cross-file dependency tracking (configurable)

### ğŸ¯ Smart TopK Cutoff
- **Anchor & Floor**: Dynamic threshold + absolute lower bound
- **Delta Guard**: Prevents misjudgment in Top1 outlier scenarios
- **Safe Harbor**: First N results only check the lower bound, ensuring basic recall

### ğŸ”Œ Native MCP Support
- **MCP Server Mode**: One-click launch of Model Context Protocol server
- **Zen Design**: Intent-term separation, LLM-friendly API design
- **Auto-Indexing**: First query triggers indexing automatically, incremental updates are transparent

### âœï¸ Prompt Enhancer
- **Multi-LLM Support**: Switch between OpenAI / Claude / Gemini with one config
- **Three Interaction Modes**: MCP tool call, CLI command, Web UI browser interaction
- **Auto Language Detection**: Chinese input automatically gets Chinese output
- **Custom Templates**: Support for custom enhancement prompt templates

## ğŸ“¦ Quick Start

### Requirements

- Node.js >= 20
- pnpm (recommended) or npm

### Installation

```bash
# Global install (enhanced version with Prompt Enhancer)
npm install -g @lyy0709/contextweaver

# Or using pnpm
pnpm add -g @lyy0709/contextweaver
```

### Initialize Configuration

```bash
# Create config file (~/.contextweaver/.env)
contextweaver init
# Or shorthand
cw init
```

Edit `~/.contextweaver/.env` and fill in your API keys:

```bash
# Embedding API (required)
EMBEDDINGS_API_KEY=your-api-key-here
EMBEDDINGS_BASE_URL=https://api.siliconflow.cn/v1/embeddings
EMBEDDINGS_MODEL=BAAI/bge-m3
EMBEDDINGS_MAX_CONCURRENCY=10
EMBEDDINGS_DIMENSIONS=1024

# Reranker (required)
RERANK_API_KEY=your-api-key-here
RERANK_BASE_URL=https://api.siliconflow.cn/v1/rerank
RERANK_MODEL=BAAI/bge-reranker-v2-m3
RERANK_TOP_N=20

# Ignore patterns (optional, comma-separated)
# IGNORE_PATTERNS=.venv,node_modules

# Prompt Enhancer (optional, required when using enhance / enhance-prompt)
# PROMPT_ENHANCER_ENDPOINT=openai          # Endpoint: openai / claude / gemini
# PROMPT_ENHANCER_BASE_URL=                # Custom API URL (for proxies, etc.)
# PROMPT_ENHANCER_TOKEN=your-api-key-here  # API key (required for enhance)
# PROMPT_ENHANCER_MODEL=                   # Custom model override
# PROMPT_ENHANCER_TEMPLATE=                # Custom template file path
```

### Index a Codebase

```bash
# Index current directory
contextweaver index

# Index a specific path
contextweaver index /path/to/your/project

# Force re-index
contextweaver index --force
```

### Local Search

```bash
# Semantic search
cw search --information-request "How is user authentication implemented?"

# With exact terms
cw search --information-request "Database connection logic" --technical-terms "DatabasePool,Connection"
```

### Prompt Enhancement

<p align="center">
  <img src="docs/prompt-enhancer-ui.png" alt="Prompt Enhancer Web UI" width="800" />
</p>

```bash
# Launch Web UI for interactive editing (default)
cw enhance "Implement a cached semantic search"

# Direct output to stdout
cw enhance "Implement a cached semantic search" --no-browser

# Specify endpoint temporarily (openai/claude/gemini)
cw enhance "Implement a cached semantic search" --endpoint claude --no-browser
```

### Start MCP Server

```bash
# Start MCP server (for Claude and other AI assistants)
contextweaver mcp
```

## ğŸ”§ MCP Integration

### Claude Desktop / Claude Code Configuration

Add to your config file:

```json
{
  "mcpServers": {
    "contextweaver": {
      "command": "contextweaver",
      "args": ["mcp"]
    }
  }
}
```

### MCP Tools

ContextWeaver provides two MCP tools:

- `codebase-retrieval`: Codebase search (primary tool)
- `enhance-prompt`: Prompt enhancement (optional, requires external LLM API config)

#### `codebase-retrieval` Parameters

| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `repo_path` | string | âœ… | Absolute path to the repository root |
| `information_request` | string | âœ… | Semantic intent in natural language |
| `technical_terms` | string[] | âŒ | Exact technical terms (class names, function names, etc.) |

#### Zen Design Philosophy

- **Intent-Term Separation**: `information_request` describes "what to do", `technical_terms` filters "what it's called"
- **Golden Defaults**: Provides same-file context, no cross-file crawling by default
- **Agent Autonomy**: The tool only locates; cross-file exploration is driven by the Agent

#### `enhance-prompt` Parameters

| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `prompt` | string | âœ… | The original prompt to enhance |
| `conversation_history` | string | âŒ | Conversation history (`User: ...\nAssistant: ...`) |
| `project_root_path` | string | âŒ | Project root path for context |

#### Prompt Enhancer Endpoint Defaults

| Endpoint | Default Base URL | Default Model |
|----------|-----------------|---------------|
| `openai` | `https://api.openai.com/v1/chat/completions` | `gpt-4o-mini` |
| `claude` | `https://api.anthropic.com/v1/messages` | `claude-sonnet-4-20250514` |
| `gemini` | `https://generativelanguage.googleapis.com/v1beta` | `gemini-2.0-flash` |

## ğŸ—ï¸ Architecture

```mermaid
flowchart TB
    subgraph Interface["CLI / MCP Interface"]
        CLI[contextweaver CLI]
        MCP[MCP Server]
    end

    subgraph Search["SearchService"]
        VR[Vector Retrieval]
        LR[Lexical Retrieval]
        RRF[RRF Fusion + Rerank]
        VR --> RRF
        LR --> RRF
    end

    subgraph Expand["Context Expansion"]
        GE[GraphExpander]
        CP[ContextPacker]
        GE --> CP
    end

    subgraph Storage["Storage Layer"]
        VS[(VectorStore<br/>LanceDB)]
        DB[(SQLite<br/>FTS5)]
    end

    subgraph Index["Indexing Pipeline"]
        CR[Crawler<br/>fdir] --> SS[SemanticSplitter<br/>Tree-sitter] --> IX[Indexer<br/>Batch Embedding]
    end

    subgraph Enhancer["Prompt Enhancer"]
        PE[enhancePrompt]
        LLM[LLM Adapters<br/>OpenAI / Claude / Gemini]
        WEB[Web UI Server]
        PE --> LLM
        PE --> WEB
    end

    Interface --> Search
    Interface --> Enhancer
    RRF --> GE
    Search <--> Storage
    Expand <--> Storage
    Index --> Storage
```

### Core Modules

| Module | Responsibility |
|--------|---------------|
| **SearchService** | Hybrid search core: vector/lexical recall, RRF fusion, reranking |
| **GraphExpander** | Context expander: E1/E2/E3 three-phase expansion |
| **ContextPacker** | Context packer: paragraph merging and token budget control |
| **VectorStore** | LanceDB adapter: vector index CRUD |
| **SQLite (FTS5)** | Metadata storage + full-text search index |
| **SemanticSplitter** | AST semantic chunker based on Tree-sitter |
| **Prompt Enhancer** | Prompt enhancement: multi-LLM adapters, Web UI interaction |

## ğŸ“ Project Structure

```
contextweaver/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts              # CLI entry point
â”‚   â”œâ”€â”€ config.ts             # Configuration (environment variables)
â”‚   â”œâ”€â”€ api/                  # External API clients
â”‚   â”‚   â”œâ”€â”€ embed.ts          # Embedding API
â”‚   â”‚   â””â”€â”€ rerank.ts         # Reranker API
â”‚   â”œâ”€â”€ chunking/             # Semantic chunking
â”‚   â”‚   â”œâ”€â”€ SemanticSplitter.ts   # AST semantic chunker
â”‚   â”‚   â”œâ”€â”€ SourceAdapter.ts      # Source adapter
â”‚   â”‚   â”œâ”€â”€ LanguageSpec.ts       # Language specifications
â”‚   â”‚   â””â”€â”€ ParserPool.ts        # Tree-sitter parser pool
â”‚   â”œâ”€â”€ scanner/              # File scanning
â”‚   â”œâ”€â”€ indexer/              # Indexing
â”‚   â”œâ”€â”€ vectorStore/          # Vector storage (LanceDB)
â”‚   â”œâ”€â”€ db/                   # Database (SQLite + FTS5)
â”‚   â”œâ”€â”€ search/               # Search service
â”‚   â”‚   â”œâ”€â”€ SearchService.ts  # Core search service
â”‚   â”‚   â”œâ”€â”€ GraphExpander.ts  # Context expander
â”‚   â”‚   â”œâ”€â”€ ContextPacker.ts  # Context packer
â”‚   â”‚   â””â”€â”€ resolvers/        # Multi-language import resolvers
â”‚   â”œâ”€â”€ enhancer/             # Prompt Enhancer
â”‚   â”‚   â”œâ”€â”€ index.ts          # Enhancement orchestration
â”‚   â”‚   â”œâ”€â”€ template.ts       # Template management
â”‚   â”‚   â”œâ”€â”€ detect.ts         # Language detection
â”‚   â”‚   â”œâ”€â”€ parser.ts         # Response parsing
â”‚   â”‚   â”œâ”€â”€ llmClient.ts      # LLM client interface + factory
â”‚   â”‚   â”œâ”€â”€ server.ts         # Web UI HTTP server
â”‚   â”‚   â”œâ”€â”€ ui.ts             # Frontend page template
â”‚   â”‚   â”œâ”€â”€ browser.ts        # Browser launcher
â”‚   â”‚   â””â”€â”€ adapters/         # LLM API adapters
â”‚   â”‚       â”œâ”€â”€ openai.ts
â”‚   â”‚       â”œâ”€â”€ claude.ts
â”‚   â”‚       â””â”€â”€ gemini.ts
â”‚   â”œâ”€â”€ mcp/                  # MCP server
â”‚   â”‚   â”œâ”€â”€ server.ts         # MCP server implementation
â”‚   â”‚   â”œâ”€â”€ main.ts           # MCP entry point
â”‚   â”‚   â””â”€â”€ tools/
â”‚   â”‚       â”œâ”€â”€ codebaseRetrieval.ts  # Code retrieval tool
â”‚   â”‚       â””â”€â”€ enhancePrompt.ts      # Prompt enhancement tool
â”‚   â””â”€â”€ utils/                # Utilities
â”‚       â””â”€â”€ logger.ts         # Logging system
â”œâ”€â”€ tests/                    # Unit tests
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ vitest.config.ts
```

## âš™ï¸ Configuration Reference

### Environment Variables

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `EMBEDDINGS_API_KEY` | âœ… | - | Embedding API key |
| `EMBEDDINGS_BASE_URL` | âœ… | - | Embedding API URL |
| `EMBEDDINGS_MODEL` | âœ… | - | Embedding model name |
| `EMBEDDINGS_MAX_CONCURRENCY` | âŒ | 10 | Embedding concurrency |
| `EMBEDDINGS_DIMENSIONS` | âŒ | 1024 | Vector dimensions |
| `RERANK_API_KEY` | âœ… | - | Reranker API key |
| `RERANK_BASE_URL` | âœ… | - | Reranker API URL |
| `RERANK_MODEL` | âœ… | - | Reranker model name |
| `RERANK_TOP_N` | âŒ | 20 | Rerank return count |
| `IGNORE_PATTERNS` | âŒ | - | Extra ignore patterns |
| `PROMPT_ENHANCER_ENDPOINT` | âŒ | `openai` | Enhancer endpoint (openai/claude/gemini) |
| `PROMPT_ENHANCER_TOKEN` | âŒ* | - | Enhancer API key (*required when using enhance) |
| `PROMPT_ENHANCER_BASE_URL` | âŒ | per endpoint | Custom enhancer API URL |
| `PROMPT_ENHANCER_MODEL` | âŒ | per endpoint | Custom enhancer model |
| `PROMPT_ENHANCER_TEMPLATE` | âŒ | - | Custom enhancer template path |

## ğŸŒ Language Support

ContextWeaver natively supports AST parsing for the following languages via Tree-sitter:

| Language | AST Parsing | Import Resolution | File Extensions |
|----------|-------------|-------------------|-----------------|
| TypeScript | âœ… | âœ… | `.ts`, `.tsx` |
| JavaScript | âœ… | âœ… | `.js`, `.jsx`, `.mjs` |
| Python | âœ… | âœ… | `.py` |
| Go | âœ… | âœ… | `.go` |
| Java | âœ… | âœ… | `.java` |
| Rust | âœ… | âœ… | `.rs` |
| C | âœ… | âœ… | `.c`, `.h` |
| C++ | âœ… | âœ… | `.cpp`, `.hpp`, `.cc`, `.cxx` |
| C# | âœ… | âœ… | `.cs` |

Other languages use a line-based fallback chunking strategy and can still be indexed and searched.

## ğŸ“Š Performance

- **Incremental Indexing**: Only processes changed files, 10x+ speedup on re-index
- **Batch Embedding**: Adaptive batch sizing with concurrency control
- **Rate Limit Recovery**: Auto-backoff on 429 errors with progressive recovery
- **Connection Pooling**: Tree-sitter parser pool reuse
- **File Index Cache**: GraphExpander file path index lazy loading

## ğŸ§ª Testing

```bash
# Run tests
pnpm test

# Watch mode
pnpm test:watch
```

## ğŸ› Logging & Debugging

Log file location: `~/.contextweaver/logs/app.YYYY-MM-DD.log`

Set log level:

```bash
# Enable debug logging
LOG_LEVEL=debug contextweaver search --information-request "..."
```

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ™ Acknowledgments

- [hsingjui/ContextWeaver](https://github.com/hsingjui/ContextWeaver) â€” Original project
- [Tree-sitter](https://tree-sitter.github.io/tree-sitter/) â€” High-performance syntax parsing
- [LanceDB](https://lancedb.com/) â€” Embedded vector database
- [MCP](https://modelcontextprotocol.io/) â€” Model Context Protocol
- [SiliconFlow](https://siliconflow.cn/) â€” Recommended Embedding/Reranker API provider

---

<p align="center">
  <sub>Made with â¤ï¸ for AI-assisted coding</sub>
</p>
